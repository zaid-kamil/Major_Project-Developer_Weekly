{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/newsletter/305'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_url = \"https://cpp.libhunt.com/newsletter\"\n",
    "page = requests.get(start_url).text\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "url = \"https://cpp.libhunt.com\"+soup.find('div',attrs={'class':'text-center text-strong-invite'}).a.attrs.get('href')\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        if page.status_code == 200:\n",
    "            soup = BeautifulSoup(page.text,'html.parser')\n",
    "            return soup\n",
    "        else:\n",
    "            print(\"page error\",page.status_code)\n",
    "            return None\n",
    "    except:\n",
    "        print(\"Internet error\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# c++ Newsletter\n",
    "final_link = []\n",
    "link = []\n",
    "topic = []\n",
    "category = []\n",
    "library_project_desc = []\n",
    "url = 'https://cpp.libhunt.com/newsletter/296'\n",
    "bsoup = get_soup(url)\n",
    "\n",
    " # finding ul from the page\n",
    "\n",
    "ul_news_article = bsoup.find('ul',class_='newsletter-stories no-bullet')\n",
    "\n",
    "# finding all the div tags from the ul\n",
    "all_div_news_article = ul_news_article.find_all('div',class_='column')\n",
    "\n",
    "# finding all the anchor tags and extractng the link and string from the anchor tag\n",
    "for achr in all_div_news_article:\n",
    "    \n",
    "    if achr.find('a',class_='thumb-wrapper'):\n",
    "        \n",
    "        link.append(achr.find('a',class_='thumb-wrapper').get('href'))\n",
    "        topic.append(achr.find('a',class_='thumb-wrapper').string)\n",
    "    if achr.find('a',class_='title'):\n",
    "        \n",
    "        link.append(achr.find('a',class_='title').get('href'))\n",
    "        topic.append(achr.find('a',class_='title').string)\n",
    "\n",
    "# removing duplicate links from the link list and adding to the new list \"final_link\"\n",
    "for item in range(0,len(link),2):\n",
    "    final_link.append(link[item])\n",
    "    category.append('Popular News and Articles')\n",
    "\n",
    "# removing the None elements form the list\n",
    "for item in topic:\n",
    "    if item == None:\n",
    "        topic.remove(item)\n",
    "\n",
    "\n",
    "# extracting links from Trending libraries and projects\n",
    "ul_library_project = bsoup.find('ul',class_='newsletter-projects no-bullet')\n",
    "lib_a = ul_library_project.find_all('a',class_='title')\n",
    "for item in lib_a:\n",
    "    final_link.append(item.get('href'))\n",
    "    topic.append(item.string)\n",
    "\n",
    "# extracting description or paragraph from the Trending libraries and projects\n",
    "ul_library_project = bsoup.find('ul',class_='newsletter-projects no-bullet')\n",
    "descrip = ul_library_project.find_all('p',class_='description')\n",
    "\n",
    "# purpose of this loop is only to make the same size of array by filling NA values\n",
    "for item in range(0,12):\n",
    "    library_project_desc.append(\"NA\")\n",
    "\n",
    "# extracting description from Trending libraries and project section\n",
    "for item in descrip:\n",
    "    category.append('Trending libraries and projects')\n",
    "    library_project_desc.append(item.string.strip())\n",
    "\n",
    "# extracting release date of newsletter\n",
    "file_date = bsoup.find('div',class_='column shrink')\n",
    "release_date = file_date.find('strong',text='Release Date').next_sibling.next_sibling.strip()\n",
    "\n",
    "# removing space and ',' from the release_date\n",
    "for item in range(len(release_date)):\n",
    "    if release_date[item]==' ':\n",
    "        r_date = release_date.replace(' ','_')\n",
    "    if release_date[item]==',':\n",
    "        newsletter_date = r_date.replace(',','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data = {\"Category\":category,\n",
    "        \"Topic\":topic,\n",
    "        \"Description\":library_project_desc,\n",
    "        \"Link\": final_link #first converting the link list into set for unique ele and then set to list bcause list is ordere\n",
    "        }\n",
    "df2 = pd.DataFrame(scraped_data)\n",
    "\n",
    "\n",
    "file_date = bsoup.find('div',class_='column shrink')\n",
    "release_date = file_date.find('strong',text='Release Date').next_sibling.next_sibling.strip()\n",
    "# print(len(release_date))\n",
    "# print(release_date)\n",
    "\n",
    "for item in range(len(release_date)):\n",
    "    if release_date[item]==' ':\n",
    "        r_date = release_date.replace(' ','_')\n",
    "    if release_date[item]==',':\n",
    "        newsletter_date = r_date.replace(',','_')\n",
    "# print(newsletter_date)\n",
    "\n",
    "df2.to_excel(f'{newsletter_date}_C++_Newsletter.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8da01e5a71448ea74f54d88afa8911010d1d12e23bc7e103d40d5def4a09152c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
